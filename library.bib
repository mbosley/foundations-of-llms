@misc{xiong2020layer,
  title           = {On Layer Normalization in the Transformer Architecture},
  author          = {Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and
                  Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan
                  and Liwei Wang and Tie-Yan Liu},
  year            = 2020,
  eprint          = {2002.04745},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.LG}
}

@misc{mikolov2013efficient,
  title           = {Efficient Estimation of Word Representations in Vector
                  Space},
  author          = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey
                  Dean},
  year            = 2013,
  eprint          = {1301.3781},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.CL}
}

@inproceedings{pennington2014glove,
  title           = "{G}lo{V}e: Global Vectors for Word Representation",
  author          = "Pennington, Jeffrey and Socher, Richard and Manning,
                  Christopher",
  booktitle       = "Proceedings of the 2014 Conference on Empirical Methods in
                  Natural Language Processing ({EMNLP})",
  month           = oct,
  year            = 2014,
  address         = "Doha, Qatar",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/D14-1162",
  doi             = "10.3115/v1/D14-1162",
  pages           = "1532--1543",
}

@inproceedings{levy2014advances,
  author          = {Levy, Omer and Goldberg, Yoav},
  booktitle       = {Advances in Neural Information Processing Systems},
  editor          = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence
                  and K.Q. Weinberger},
  publisher       = {Curran Associates, Inc.},
  title           = {Neural Word Embedding as Implicit Matrix Factorization},
  url             =
                  {https://proceedings.neurips.cc/paper_files/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf},
  volume          = 27,
  year            = 2014
}

@misc{rong2016word2vec,
  title           = {word2vec Parameter Learning Explained},
  author          = {Xin Rong},
  year            = 2016,
  eprint          = {1411.2738},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.CL}
}

@book{goodfellow2016deep,
  title           = {Deep Learning},
  author          = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher       = {MIT Press},
  note            = {\url{http://www.deeplearningbook.org}},
  year            = 2016
}

@misc{goldberg2015primer,
  title           = {A Primer on Neural Network Models for Natural Language
                  Processing},
  author          = {Yoav Goldberg},
  year            = 2015,
  eprint          = {1510.00726},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.CL}
}

@article{lecun2015deep,
  title           = {Deep learning},
  author          = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal         = {nature},
  volume          = 521,
  number          = 7553,
  pages           = {436--444},
  year            = 2015,
  publisher       = {Nature Publishing Group UK London}
}

@article{rumelhart1986learning,
  title           = {Learning representations by back-propagating errors},
  author          = {Rumelhart, David E and Hinton, Geoffrey E and Williams,
                  Ronald J},
  journal         = {nature},
  volume          = 323,
  number          = 6088,
  pages           = {533--536},
  year            = 1986,
  publisher       = {Nature Publishing Group UK London}
}

@article{elman1990finding,
  title           = {Finding structure in time},
  author          = {Elman, Jeffrey L},
  journal         = {Cognitive science},
  volume          = 14,
  number          = 2,
  pages           = {179--211},
  year            = 1990,
  publisher       = {Wiley Online Library}
}

@article{hochreiter1997long,
  title           = {Long short-term memory},
  author          = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal         = {Neural computation},
  volume          = 9,
  number          = 8,
  pages           = {1735--1780},
  year            = 1997,
  publisher       = {MIT press}
}

@article{cho2014learning,
  title           = {Learning phrase representations using RNN encoder-decoder
                  for statistical machine translation},
  author          = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre,
                  Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk,
                  Holger and Bengio, Yoshua},
  journal         = {arXiv preprint arXiv:1406.1078},
  year            = 2014
}

@electronic{karpathy2015unreasonable,
  added-at        = {2017-07-19T15:29:59.000+0200},
  author          = {Karpathy, Andrej},
  biburl          =
                  {https://www.bibsonomy.org/bibtex/236c6041ff8f00e4d94b521b3c5ebf032/andreashdez},
  citeulike-article-id= 14362000,
  citeulike-linkout-0= {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
  day             = 21,
  interhash       = {8858d78ffdad695d4d660b50c3d09660},
  intrahash       = {36c6041ff8f00e4d94b521b3c5ebf032},
  keywords        = {chm1320},
  month           = may,
  posted-at       = {2017-05-23 17:49:11},
  priority        = 2,
  timestamp       = {2017-07-19T15:31:02.000+0200},
  title           = {{The Unreasonable Effectiveness of Recurrent Neural
                  Networks}},
  url             = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
  year            = 2015
}

@misc{sutskever2014sequence,
  title           = {Sequence to Sequence Learning with Neural Networks},
  author          = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  year            = 2014,
  eprint          = {1409.3215},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.CL}
}

@article{bahdanau2014neural,
  title           = {Neural machine translation by jointly learning to align and
                  translate},
  author          = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal         = {arXiv preprint arXiv:1409.0473},
  year            = 2014
}

@article{luong2015effective,
  title           = {Effective approaches to attention-based neural machine
                  translation},
  author          = {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher
                  D},
  journal         = {arXiv preprint arXiv:1508.04025},
  year            = 2015
}

@article{vaswani2017attention,
  title           = {Attention is all you need},
  author          = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and
                  Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal         = {Advances in neural information processing systems},
  volume          = 30,
  year            = 2017
}

@inproceedings{al2019character,
  title           = {Character-level language modeling with deeper
                  self-attention},
  author          = {Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo,
                  Mandy and Jones, Llion},
  booktitle       = {Proceedings of the AAAI conference on artificial
                  intelligence},
  volume          = 33,
  number          = 01,
  pages           = {3159--3166},
  year            = 2019
}

@article{lin2017structured,
  title           = {A structured self-attentive sentence embedding},
  author          = {Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira
                  dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio,
                  Yoshua},
  journal         = {arXiv preprint arXiv:1703.03130},
  year            = 2017
}

@article{shaw2018self,
  title           = {Self-attention with relative position representations},
  author          = {Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  journal         = {arXiv preprint arXiv:1803.02155},
  year            = 2018
}

@article{li2018multi,
  title           = {Multi-head attention with disagreement regularization},
  author          = {Li, Jian and Tu, Zhaopeng and Yang, Baosong and Lyu,
                  Michael R and Zhang, Tong},
  journal         = {arXiv preprint arXiv:1810.10183},
  year            = 2018
}

@article{clark2019does,
  title           = {What does bert look at? an analysis of bert's attention},
  author          = {Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and
                  Manning, Christopher D},
  journal         = {arXiv preprint arXiv:1906.04341},
  year            = 2019
}

@article{devlin2018bert,
  title           = {Bert: Pre-training of deep bidirectional transformers for
                  language understanding},
  author          = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and
                  Toutanova, Kristina},
  journal         = {arXiv preprint arXiv:1810.04805},
  year            = 2018
}

@article{radford2018improving,
  title           = {Improving language understanding by generative
                  pre-training},
  author          = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and
                  Sutskever, Ilya and others},
  year            = 2018,
  publisher       = {OpenAI}
}

@article{liu2019roberta,
  title           = {Roberta: A robustly optimized bert pretraining approach},
  author          = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei
                  and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis,
                  Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal         = {arXiv preprint arXiv:1907.11692},
  year            = 2019
}

@article{raffel2020exploring,
  title           = {Exploring the limits of transfer learning with a unified
                  text-to-text transformer},
  author          = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee,
                  Katherine and Narang, Sharan and Matena, Michael and Zhou,
                  Yanqi and Li, Wei and Liu, Peter J},
  journal         = {The Journal of Machine Learning Research},
  volume          = 21,
  number          = 1,
  pages           = {5485--5551},
  year            = 2020,
  publisher       = {JMLRORG}
}

@article{radford2019language,
  title           = {Language models are unsupervised multitask learners},
  author          = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan,
                  David and Amodei, Dario and Sutskever, Ilya and others},
  journal         = {OpenAI blog},
  volume          = 1,
  number          = 8,
  pages           = 9,
  year            = 2019
}

@article{brown2020language,
  title           = {Language models are few-shot learners},
  author          = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah,
                  Melanie and Kaplan, Jared D and Dhariwal, Prafulla and
                  Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and
                  Askell, Amanda and others},
  journal         = {Advances in neural information processing systems},
  volume          = 33,
  pages           = {1877--1901},
  year            = 2020
}

@article{wang2018can,
  title           = {Can you tell me how to get past sesame street?
                  sentence-level pretraining beyond language modeling},
  author          = {Wang, Alex and Hula, Jan and Xia, Patrick and Pappagari,
                  Raghavendra and McCoy, R Thomas and Patel, Roma and Kim,
                  Najoung and Tenney, Ian and Huang, Yinghui and Yu, Katherin
                  and others},
  journal         = {arXiv preprint arXiv:1812.10860},
  year            = 2018
}

@article{howard2018universal,
  title           = {Universal language model fine-tuning for text
                  classification},
  author          = {Howard, Jeremy and Ruder, Sebastian},
  journal         = {arXiv preprint arXiv:1801.06146},
  year            = 2018
}

@phdthesis{ruder2019neural,
  title           = {Neural transfer learning for natural language processing},
  author          = {Ruder, Sebastian},
  year            = 2019,
  school          = {NUI Galway}
}

@article{gururangan2018annotation,
  title           = {Annotation artifacts in natural language inference data},
  author          = {Gururangan, Suchin and Swayamdipta, Swabha and Levy, Omer
                  and Schwartz, Roy and Bowman, Samuel R and Smith, Noah A},
  journal         = {arXiv preprint arXiv:1803.02324},
  year            = 2018
}

@article{conneau2019unsupervised,
  title           = {Unsupervised cross-lingual representation learning at
                  scale},
  author          = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman
                  and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n,
                  Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer,
                  Luke and Stoyanov, Veselin},
  journal         = {arXiv preprint arXiv:1911.02116},
  year            = 2019
}
@misc{bubeck2023sparks,
  title           = {Sparks of Artificial General Intelligence: Early
                  experiments with GPT-4},
  author          = {SÃ©bastien Bubeck and Varun Chandrasekaran and Ronen Eldan
                  and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter
                  Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and
                  Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi
                  Zhang},
  year            = 2023,
  eprint          = {2303.12712},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.CL}
}
